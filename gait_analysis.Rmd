---
title: "Analysis of Gait Variability with FBAM"
author: "Connor Brubaker"
output: html_document
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
set.seed(451)
```

```{r setup, echo=FALSE, warning=FALSE, message=FALSE}
library(fbam)
library(readr)
library(dplyr)
library(stringr)
library(ggplot2)
library(tidyr)
library(patchwork)
```

In this vignette, we demonstrate the use of the FBAM package to replicate the analysis of gait variability data [@hausdorff_dynamic_2000] in the article that outlines the FBAM method. The study included  

**Note**. *The data used in this analysis can be obtained directly from [PhysioNet](https://physionet.org) at this [link](https://physionet.org/content/gaitndd/1.0.0/). The version of the data used here was retrieved on October 31, 2024.*

## Signal Pre-Processing

Here we process the original stride interval series from PhysioNet so that multitaper estimates can be obtained. We flag outliers in each signal as points that lie above and below the 96th and 1st percentiles, respectively, which are then imputed by an exponentially weighted moving average model using `na_ma()` function from the `imputeTS` package [@moritz_imputets_2017]. Linear interpolants of the outlier filtered stride intervals are then sampled at 2Hz and linear trends are removed. Finally, each resulting signal is standardized. 

```{r signal_processing}
# get data that was obtained on 10-31-2024 from within the fbam package
# this directory is where the data files are stored locally for manual inspection
data_dir <- system.file("extdata/gaitndd-10312024/", package = "fbam")
ts_files <- list.files(data_dir, pattern = "\\.ts$", full.names = T)
subjectID <- tools::file_path_sans_ext(basename(ts_files))  # als1, control1, etc.
labels <- gsub("[0-9]", "", subjectID) # als, control, hunt, or park

# the following patients were removed due to the presence of too many outliers
removed <- c("als12", "als4", "park11")
ts_files <- ts_files[!subjectID %in% removed]
labels <- labels[!subjectID %in% removed]
subjectID <- subjectID[!subjectID %in% removed]
npatients <- length(subjectID)  # number of resulting patients

# the resulting signals represent 210 seconds of walking time and are of length
# T = 420 observations. Note that these do not directly represent steps. 
duration <- 210 # seconds
sample_rate <- 2 # samples per second
len <- duration * sample_rate # 420 observations
freq <- (sample_rate / len) * 1:(floor(len / 2) - 1)
ntapers <- floor(sqrt(len))

x <- matrix(nrow = len, ncol = npatients) # time series data
mtspec <- matrix(nrow = length(freq), ncol = npatients) # multitaper estimates
for (i in 1:npatients) {
  dat <- read.delim(ts_files[i], header = FALSE)
  elapsed_time <- dat[[1]]
  left_stride <- dat[[2]]
  
  # outlier filtering using percentiles of current signal
  quantiles <- quantile(left_stride, c(0.01, 0.96))
  left_stride[left_stride < quantiles[1] | left_stride > quantiles[2]] <- NA
  left_stride <- imputeTS::na_ma(left_stride, k = 4) # use two seconds on both sides

  # linear interpolation and sampling 
  start_time <- min(elapsed_time)
  grid <- seq(from = start_time, by = 1 / sample_rate, length = len)
  left_stride <- approx(x = elapsed_time, y = left_stride, xout = grid)$y

  # remove linear trend, standardize, and obtain multitaper estimate
  left_stride <- as.vector(gsignal::detrend(left_stride, p = 1))
  x[, i] <- left_stride / sd(left_stride)
  mtspec[,i] <- sine_mt(x[, i])$mtspec
}
```

The top row of the figure below shows the resulting stride interval series from a representative subject from each of the four groups in the study. The bottom row shows all multitaper estimated (normalized) power spectra from all subjects in the corresponding group above. 

```{r data_plotting, echo=FALSE, fig.align='center', fig.height=4, fig.width=7.25}
par(mfrow = c(2, 4))
groups <- c('control', 'als', 'hunt', 'park')
group_names <- c('Control', 'ALS', 'Huntington\'s', 'Parkinson\'s')
time <- seq(1, by = 0.5, length = len)

# top row: time series
ts_plots <- lapply(1:length(groups), function(i) {
  group_x <- x[, labels == groups[i]]
  display_x <- group_x[, 1]
  ggplot() +
    geom_line(aes(x = time, y = display_x)) +
    scale_x_continuous() +
    labs(x = 'Time (seconds)', y = 'Seconds', title = group_names[i]) +
    theme_bw() +
    theme(plot.title = element_text(hjust = 0.5)) +
    ylim(min(x), max(x))
})

mt_plots <- lapply(1:length(groups), function(i) {
  group_mt <- data.frame(t(mtspec[, labels == groups[i]])) 
  names(group_mt) <- freq
  group_mt <- group_mt %>%
    mutate(subject_id = row_number()) %>%
    pivot_longer(cols = -subject_id, names_to = "freq", values_to = "spec") %>%
    mutate(freq = as.numeric(freq))
  ggplot(data = group_mt, aes(x = freq, y = spec, group = subject_id)) +
    scale_x_continuous(breaks = seq(0, 0.5 * sample_rate, length = 3)) +
    geom_line(linewidth = 0.25) +
    labs(x = "Hz", y = "Power") +
    ylim(0, max(mtspec)) +
    theme_bw()
})

wrap_plots(c(ts_plots, mt_plots), nrow = 2)
```

### Descriptors File

The original data from PhysioNet also included a subject descriptors file which includes the following information:

* The age (years), height (meters), and weight (kilograms) of the subject,
* the sex of the subject,
* the average gait speed (meters/sec) of the subject during the observed stride, and
* a measure of duration or severity of disease.

For subjects with PD, the severity is measured by the Hohn and Yahr score (a higher score indicates more advanced disease). For subjects with HD, this is measured by the total functional capacity measure (TFCM; a lower score indicates more advanced functional impairment). For the subjects with ALS, duration is defined as the time in months since diagnosis. For the control subjects, 0 is used as a place holder.

To facilitate comparisons of disease severity across groups, we compute a standardized measure of severity for each subject so that a score of 0 corresponds to least severe and 1 corresponds to most severe. For subjects with Huntington's disease, the total functional capacity measure ranges from 0 to 13 where 0 indicates no functional capacity and 13 indicates fully independent with minimal symptoms. The standardized score of the $k$th HD subject is defined as 
$$
\mathrm{Standardized\ HD\ Score}_k = 1 - \frac{\mathrm{TFCM}_k}{13}
$$
where $\mathrm{TFCM}_k$ is the total functional capacity measure of the $k$th HD subject. For PD subjects, the Hohn and Yahr score ranges from 1 to 5 where 5 indicates the most severe disease. The standardized score of the $k$th PD subject is consequently defined as 
$$
\mathrm{Standardized\ PD\ Score}_k = \frac15(\mathrm{HY}_k - 1)
$$
where $\mathrm{HY}_k$ is the Hohn and Yahr score of the $k$th PD subject. Finally, for ALS subjects, since ALS generally progresses with age (albeit at different rates between subjects), we define the standardized "severity" score for the $k$th ALS patient as 
$$
\mathrm{Standardized\ ALS\ Score}_k = \frac{\mathrm{D}_k - \min_{k\in\mathrm{ALS}}\mathrm{D}}{\max_{k\in\mathrm{ALS}}\mathrm{D} - \min_{k\in\mathrm{ALS}}\mathrm{D}}
$$
where $\min_{k\in\mathrm{ALS}}\mathrm{D}$ and $\max_{k\in\mathrm{ALS}}\mathrm{D}$ are the minimum and maximum times since diagnosis among the ALS subjects, respectively. 

**Note**. The original `subject-description.txt` file from PhysioNet contains a typo on lines 37-38 (among other formatting issues). The TFCM score for subject `hunt20` was included alone on line 38 whereas it should have been included at the end of line 37. The author of this vignette has manually fixed this and has converted the original file to a `.csv` for easier reading. 

```{r covariates}
# read in data and impute missing values
desc <- read_csv(paste0(data_dir, 'subject-description.csv'), na = "MISSING",
                 show_col_types = FALSE) %>%
  mutate(group = str_replace_all(group, "subjects", "als")) %>%
  mutate(group = factor(group, levels = c('control', 'als', 'hunt', 'park'),
                        labels = c("Control", "ALS", "HD", "PD"))) %>%
  group_by(group) %>%
  mutate(across(where(is.numeric), ~ if_else(is.na(.), mean(., na.rm = TRUE), .))) %>%
  ungroup() %>%
  filter(!subjectID %in% removed) # remove same subjects as above

# standardization of duration and severity scores
als_ds_bounds <- desc %>% filter(group == 'ALS') %>% 
  summarise(min = min(ds), max = max(ds)) %>% as.integer()
desc <- max_als_ds <- desc %>% 
  mutate(ds_std = case_when(
    group == "HD" ~ 1 - (ds / 13),
    group == "PD" ~ (ds - 1) / 5,
    group == "ALS" ~ (ds - als_ds_bounds[1]) / (als_ds_bounds[2] - als_ds_bounds[1]),
    group == "Control" ~ 0
  ))
print(head(desc))
```

## Analysis with FBAM

We now use FBAM to achieve two goals with the gait variability data:

1. Estimate a single set of frequency bands for the entire population and 
2. simultaneously partition subjects into subpopulations with different spectral dynamics and estimate a set of frequency bands for each subpopulation. In both cases, the number of frequency bands will be chosen from between 2 and 6, inclusive, and is set by the `nbands` parameter in the call to `fbam`. In the latter case, the number of subpopulations will be jointly selected from values also between 2 and 6, inclusive, and is set by the `nsubpop` parameter. This is done in parallel by setting the `parallel` parameter to an integer greater than `1`. 

```{r run_fbam, cache=TRUE}
ncores <- parallel::detectCores() - 1 # use all cores except 1
fbam_all <- fbam(x, nbands = 2:6, nsubpop = 1, sample_rate = sample_rate, 
                 parallel = ncores)
fbam_subpop <- fbam(x, nbands = 2:6, nsubpop = 2:6, sample_rate = sample_rate,
                    parallel = ncores)
```

A call to `fbam` will (always) return a list with two components. The first of these, `selected_solution` is the solution chosen by minimization of the validation criteria. The second of these, `all_solutions`, is another list with the outputs from the evolutionary algorithm over the grid of requested parameters `nbands` and `nsubpop`. Each of these entires as well as the object `selected_solution` is of the class `ea_output` which has `print` and `plot` generics. Below is the summary output for the frequency bands estimated for the entire population. Here, FBAM selected two frequency bands.

```{r}
print(fbam_all$selected_solution)
```

Below is the summary output for the frequency bands estimated for subpopulations found in the population of interest. Here FBAM suggested 2 subpopulations with 2 frequency bands each. For either, we will refer to the first band as the low-frequency (LF) band and the
second band as the high-frequency (HF) band. 

```{r}
print(fbam_subpop$selected_solution)
```

We will use the summary measures computed above in the remainder of this analysis,
so we will add them to the `desc` data frame. 

```{r}
summary <- data.frame(subjectID = subjectID, 
                 all_lf = fbam_all$selected_solution$rep_summary[,1],
                 all_hf = fbam_all$selected_solution$rep_summary[,2],
                 subpop_label = fbam_subpop$selected_solution$labels,
                 subpop_lf = fbam_subpop$selected_solution$rep_summary[,1],
                 subpop_hf = fbam_subpop$selected_solution$rep_summary[,2])
desc <- inner_join(desc, summary, by = "subjectID")
```


## Differences in Summary Measures

In this section, we evaluate the degree to which FBAM has preserved
differences between groups in terms of the summary measures derived from the 
frequency bands it has estimated for the entire population. To do so, we consider
every possible frequency band boundary that could form two bands. For each candidate
boundary, we take the resulting set of replicate-specific collapsed measures in the LF band
and use the Kruskal-Wallis test to evaluate whether a difference exists between at least one pair of groups. 

```{r kw_pvalues, fig.align='center', fig.height=3, fig.width=8}
par(mfrow = c(1, 3))

# compute KW p-value for each candidate frequency band boundary
w <- seq(2, nrow(mtspec)) # candidate boundaries
pvalues <- unlist(lapply(w, function(x) {
  rep_summary_mat <- fbam:::rep_summary(mtspec, x)
  return(kruskal.test(rep_summary_mat[,1] ~ labels)$p.value)
}))
```

```{r, fig.align='center', fig.width=7.25, fig.height=2.75}
# visualize
pvalues_df <- data.frame(w = freq[w], pvalues = pvalues)
p1 <- plot(fbam_all$selected_solution)
p2 <- ggplot(data = desc, aes(x = group, y = all_lf)) +
  geom_boxplot() +
  geom_jitter(shape = 16, position = position_jitter(0.2)) +
  labs(x = "Group", y = "LF Power") +
  theme_bw()
p3 <- ggplot(data = pvalues_df, aes(x = w, y = log(pvalues))) +
  geom_line() +
  geom_vline(xintercept = fbam_all$selected_solution$endpoints, 
             linetype = 'dashed', color = 'red') +
  geom_hline(yintercept = log(0.05), linetype = 'dashed') +
  labs(x = 'Hz', y = 'Logarithm of p-value') +
  theme_bw()
p1 + p2 + p3
```

## Subpopulation analysis

Below is a visualization of the subpopulations and associated frequency bands 
estimated by FBAM. 

```{r, fig.align='center', fig.width=7.25, fig.height=4}
plot(fbam_subpop$selected_solution)
```

The table below displays how subjects across the four conditions are organized
into the two subpopulations estimated by FBAM. The subpopulations seems to differ
most in terms of their control versus HD subject membership while the ALS subjects
are primarily sorted with the controls and the PD subjects are almost evenly split 
between the two. 

```{r}
table(fbam_subpop$selected_solution$labels, labels)
```

We now look to see if any physiological differences exist between the two 
subpopulations in terms of age, height, or any of the other subject-level
descriptors included in the data. Below are the median and median absolute deviation for
the numeric covariates among each of the subpopulations.

```{r}
cols <- c("age", "height", "weight", "gait_speed", "ds_std")
# median
desc %>%
  group_by(subpop_label) %>%
  select(all_of(cols)) %>%
  summarise(across(all_of(cols), list(median = median)))

# mad
desc %>%
  group_by(subpop_label) %>%
  select(all_of(cols)) %>%
  summarise(across(all_of(cols), list(mad = mad)))
```




```{r, fig.align='center', fig.width=7.25, fig.height=1.75}
cols <- c("age", "height", "weight", "gait_speed", "ds_std")
bplots <- lapply(cols, function(x) {
  desc %>% select(x, subpop_label) %>%
  pivot_longer(x, names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = variable, y = value, group = subpop_label)) +
  geom_boxplot()
})
wrap_plots(bplots, nrow = 1)
```

We can see from these output that while height, weight, and gait speed don't appear to 
significantly differ between the groups, age and the standardized severity scores might. 
To confirm this, we use the Wilcoxon rank-sum test.

```{r, warning=T}
for (col in cols) {
  x <- desc %>% dplyr::filter(subpop_label == 1) %>% select(all_of(col)) %>% unlist()
  y <- desc %>% dplyr::filter(subpop_label == 2) %>% select(all_of(col)) %>% unlist()
  pval <- wilcox.test(x = x, y = y, exact = FALSE)$p.value
  cat('Wilcoxon p-value for variable ', col, ': ', round(pval, 6), '\n', sep = '')
}
```

The conclusion is that different frequency band definitions are certainly needed
when analyzing older populations with more advanced neurodegenerative disease
relative to younger populations with less severe disease. 

## Informative Capacity of Summary Measures

Finally, we want to evaluate the informative capacity of the summary measures
in two ways. First, can these summary measures help us predict the presence
of HD compared to a baseline model? Second, what is the nature of the relationship
between these summary measures and the severity of disease among HD subjects?

To answer the first question, we use a logistic regression model to perform
the binary classification task of HD versus everything else. We will first
build a baseline model using age, height, and gait speed and then build a comparison
model by adding the LF, HF, or ratio of LF to HF summary measure of power from 
the bands estimated for the entire population. To estimate out of sample test 
error, we use $6$-fold cross validation. 

```{r}
desc_complete <- desc[complete.cases(desc), ] %>%
  mutate(hd = ifelse(group == "HD", 1, 0))

nfolds <- 6; nsamples <- nrow(desc_complete)
fold_id <- sample(c(
  rep(1:nfolds, each = floor(nsamples / nfolds)),
  1:(nsamples %% nfolds)
))

base_acc <- lf_acc <- rep(0, nfolds)
for (i in 1:nfolds) {
  train <- desc_complete[fold_id != i, ]; test <- desc_complete[fold_id == i, ]
  glm_base <- glm(hd ~ age + height + gait_speed, 
                  data = train, family = binomial())
  glm_lf <- glm(hd ~ age + height + gait_speed + all_lf, 
                data = train, family = binomial())
  base_pred <- as.numeric(predict(glm_base, newdata = test, type = 'response') > 0.5)
  lf_pred <- as.numeric(predict(glm_lf, newdata = test, type = 'response') > 0.5)
  base_acc[i] <- mean(base_pred == test$hd)
  lf_acc[i] <- mean(lf_pred == test$hd)
}

cat(paste0('Accuracy for baseline model: ', round(mean(base_acc), 4), ' (', 
           round(sd(base_acc), 4), ')', '\n'))
cat(paste0('Accuracy with added LF measures: ', round(mean(lf_acc), 4), 
           ' (', round(sd(lf_acc), 4), ')', '\n'))
```

We now evaluate the accuracy of the expanded model with the LF summary measures
over a varying definition of the frequency bands as before. 

```{r lr_bands, fig.align='center', fig.width=7.25, fig.height=4}
w <- seq(2, nrow(mtspec)) # candidate boundaries
accuracy <- lapply(w, function(x) {
  rep_summary_mat <- fbam:::rep_summary(mtspec, x)
  current_lf <- data.frame(
    subjectID = subjectID,
    current_lf = rep_summary_mat[,1]
  )
  desc_complete_current <- inner_join(desc_complete, current_lf, by = "subjectID")
  
  acc <- rep(0, nfolds)
  for (i in 1:nfolds) {
    train <- desc_complete_current[fold_id != i, ]
    test <- desc_complete_current[fold_id == i, ]
    glm_fit <- glm(hd ~ age + height + gait_speed + current_lf, 
                  data = train, family = binomial())
    pred <- as.numeric(predict(glm_fit, newdata = test, type = 'response') > 0.5)
    acc[i] <- mean(pred == test$hd)
  }
  return(data.frame(freq = freq[x], mean = mean(acc), sd = sd(acc)))
})
accuracy <- do.call(rbind, accuracy)
accuracy$upper <- accuracy$mean + accuracy$sd
accuracy$lower <- accuracy$mean - accuracy$sd

ggplot(data = accuracy, aes(x = freq)) +
  geom_line(aes(y = mean)) +
  geom_line(aes(y = upper, color = "red"), linetype = "dashed") +
  geom_line(aes(y = lower, color = "red"), linetype = "dashed") +
  geom_vline(xintercept = fbam_all$selected_solution$endpoints, color = "blue") +
  geom_hline(yintercept = max(accuracy$mean), color = "blue") +
  geom_hline(yintercept = mean(base_acc), color = "purple") +
  theme_bw() +
  labs(x = "Frequency Band Boundary", y = "Accuracy", 
       title = "LR Accuracy with Varying Frequency Band Boundary") +
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))
  
```

The black solid line displays the mean cross-validated accuracy with a varying
definition for the LF band while the red dashed lines show plus or minus one
standard error, respectively. The blue vertical and horizontal lines indicate
the FBAM estimated LF boundary and the maximum accuracy over all LF band definitions,
respectively. The purple solid line marks the mean cross-validated accuracy of
the previously constructed baseline model. Hence, the LF band defined by FBAM 
nearly achieves the greatest cross-validated accuracy. 

## References

<div id="refs"></div>
